---
title: "SCR Data Summary"
format: 
  html:
    number-sections: true
---

```{r}
#| echo: true
#| code-fold: true
#| message: false
library(purrr)
library(skimr)
library(here)
library(tidyverse)
load(here("data", "clean", "data_xlsx.RData"), verbose = TRUE)
load(here("data", "clean", "data_1_no_repeat_all.RData"), verbose = TRUE)
load(here("data", "clean", "data_2_combine_ext.RData"), verbose = TRUE)
load(here("data", "clean", "data_3_no_missing.RData"), verbose = TRUE)   
```

## Data Cleaning

### Raw data `data_xlsx`

The raw data `data_xlsx` loaded from `./data/raw/2024-07-16_FSARS_EDA_Long_V2_101-269.xlsx` contains 124 subjects.

```{r}
data_xlsx
```

```{r}
length(unique(data_xlsx[["id"]]))
```


### Cleaned data `data_no_repeat_all`


I first clean the dataset. I found that some trial numbers are repeated twice. One has reaction and cs variable values, and the other has no or missing values. I keep the row whose trial has values. The data set that removes all repeated trials with no values is saved in `data_no_repeat_all`.

```{r}
data_no_repeat_all
```

Note that each subject has 4 runs, 5 conditions, and 8 trials, so we have $124\times 4 \times 5 \times 8 = 19840$ rows.

Also, we usually use `snake_case` to name variables, and set character values. So the variable `condition` has values "safety", "reward_safety", "fear_safety", "reward", "fear". The variable `run` will later change its values to "learn", "run1", "run2", and "run3".

The variable `condition` is of type `factor` having levels 
```{r}
class(data_no_repeat_all$condition)
levels(data_no_repeat_all$condition)
```

Levels: safety reward_safety fear_safety reward fear


### Cleaned data `data_combine_ext`

Based on `data_no_repeat_all`, with Jacklynn's comments, for the `run` variable, I further merge `Extincti` and `Run3`, renaming all `Ectincti`s as `Run3`. The saved data set is `data_combine_ext`. Also note that the variable `run`'s value has been changed to `r unique(data_combine_ext$run)`.

```{r}
table(data_no_repeat_all$run)
table(data_combine_ext$run)
```

### Cleaned data `data_no_missing`

The data further cleaned is `data_no_missing` that removes all rows with no reaction values or physiological response. There are 2229 trials among 224 subjects that have physiological responses.

```{r}
data_no_missing
```

In the experiment, ID 238 and 239 do not have any reaction values, or physiological response to any trials. Both participants are removed.

```{r}
setdiff(unique(data_xlsx$id), unique(data_no_missing$id))
```

Later we use `data_no_missing` for analysis. We can always go back to other data sets or the raw data when we need to. The code for cleaning data is saved in `01-data.R`.


## Data Summary

### Frequency 

The frequency table of `run` is

```{r}
data <- data_no_missing
(freq_react_run <- data |> select(run) |> table() )
```

**Findings**: (Just observed results from data, not formal statistical inference)

- **Learning round has more reactions, and frequency of reaction decays with time passed.**


We can check the contingency table of `run` and `condition`.

```{r}
#| echo: true
#| code-fold: true
freq_react_run_cond <- data |> group_by(run) |> select(run, condition) |> 
    table()
freq_react_run_cond <- cbind(freq_react_run_cond, freq_react_run)
freq_react_run_cond <- rbind(freq_react_run_cond, apply(freq_react_run_cond, 2, sum))
freq_react_run_cond
round(freq_react_run_cond / max(freq_react_run_cond), 2)
```


**Findings**: (Just observed results from data, not formal statistical inference)

- **Participants have more physiological responses to condition `fear`.**
- **For other conditions, their number of responses are not very different.**
- **The number of responses with `fear` and `reward` decreases faster. (Check their percentage).**



I then check how `condition` and `trial` are associated with the response frequencies. Frequencies with and without Learning run are both considered.

**Findings**: (Just observed results from data, not formal statistical inference)

- **Participants tend to have reactions in the first trial, especially for "fear" condition.**
- **The number of physiological response is decreasing with trial orders when the learning run is included.**
- **The decreasing pattern is not obvious for other condition types when the learning run is not included.**
- **The number seems to increase back a little bit in 7th and 8th trial.**



```{r}
#| echo: true
#| code-fold: true
#| message: false
data_cond_trial <- data |> group_by(condition) |> select(trial) |> table()

par(mfrow = c(2, 3), mar = c(4, 4, 2, 1))
for (i in seq_along(rownames(data_cond_trial))) {
    barplot(data_cond_trial[i, ], 
            main = paste(rownames(data_cond_trial)[i], "w/ learn"), las = 1,
            xlab = "trial", ylab = "number of reactions", ylim = c(0, 120))
}
```


```{r}
#| echo: true
#| code-fold: true
#| message: false
## remove learn run
data_cond_trial_no_learn <- data |> group_by(condition) |> 
    filter(run != "learn") |> 
    select(trial) |> 
    table()

par(mfrow = c(2, 3), mar = c(4, 4, 2, 1))
for (i in seq_along(rownames(data_cond_trial_no_learn))) {
    barplot(data_cond_trial_no_learn[i, ], 
            main = paste(rownames(data_cond_trial)[i], "w/o learn"), las = 1,
            xlab = "trial", ylab = "number of reactions", ylim = c(0, 85))
}
```


### Summary statistics for CS related variables

[Note:] *The learning run is removed from the analysis*.

Here I summarize all the CS related variables except `cs_stim_time` that is irrelevant to our study. The summary statistics include the minimum value, 1st quartile (25% percentile), median (50% percentile), 3rd quartile (75% percentile), maximum value, and the standard deviation. 

Here the statistics are summarized by trial condition.

**Findings**: (Just observed results from data, not formal statistical inference)

- Hard to see and conclude any effect of condition on the cs related variables. We can discuss it later.

- One thing I'm confused is that some amplitudes are ZERO. I wonder if it is a typo.


```{r}
#| echo: true
#| code-fold: true
data_split_cond <- data |> 
    filter(run != "learn") %>%
    split(.$condition)

cs_sum_cond <- lapply(data_split_cond, function(x) apply(x[, -c(1:5)], 2, summary))
cs_sd_cond <- lapply(data_split_cond, function(x) apply(x[, -c(1:5)], 2, sd))
cs_summ_cond <- vector("list", 5)
for (i in 1:5) {
    cs_summ_cond[[i]] <- rbind(cs_sum_cond[[i]], cs_sd_cond[[i]])
    rownames(cs_summ_cond[[i]]) <-
        c("min", "1stQ", "med", "mean", "3rdQ", "max", "sd")
}
names(cs_summ_cond) <- levels(data$condition)
lapply(cs_summ_cond, function(x) round(x, digits = 3))
```

Here shows the data that have amplitude value zero.

```{r}
lapply(data_split_cond, function(x) {
    if (length(which(x$cs_amplitude == 0)) > 0) {
        x[which(x$cs_amplitude == 0), ]
    }})
```


```{r}
#| echo: true
#| code-fold: true
cs_var_name <- c("Base Level",
                 "Latency",
                 "Amplitude",
                 "Rise Time",
                 "Reaction Size",
                 "Onset")
for (k in seq_along(names(data_split_cond[[1]][-c(1:5)]))) {
    par(mfrow = c(2, 3), mar = c(4, 4, 2, 1))
    lapply(1:5, function(x) hist(data_split_cond[[x]][[k+5]],
                                 main = names(data_split_cond)[x],
                                 xlab = cs_var_name[k], las = 1, 
                                 font.lab = 2, breaks = 15))
}
```


The summary grouped by cs variables is shown below.

```{r}
#| echo: true
#| code-fold: true
cs_summ_cond_var <- vector("list", length(names(data_split_cond[[1]][-c(1:5)])))

for (k in seq_along(names(data_split_cond[[1]][-c(1:5)]))) {
    cs_summ_cond_var[[k]] <- sapply(cs_summ_cond, function(x) x[, k])
}
names(cs_summ_cond_var) <- colnames(data_no_missing)[-c(1:5)]
lapply(cs_summ_cond_var, function(x) round(x, digits = 3))
```




### Summary statistics for CS related variables with trials

In this section, I examine the summary statistics for CS related variables a bit further by including trial orders to see if there is any trial effect. Again, this is a descriptive analysis that help us somewhat know the data. A formal statistical inference is needed if we would like to make any inference conclusions.

The followings show the histograms of cs related variables by trial condition and trial order. At the bottom we have numerical summaries. Maybe there is some interesting pattern or result out there, but I can't find them at this moment. We can check more later.


```{r}
#| echo: true
#| code-fold: true
cond_levels <- levels(data$condition)

cs_cond_trial_lst <- vector("list", length(cond_levels))

for (j in seq_along(cond_levels)) {
    data_cond <- data |> 
        filter(condition == cond_levels[j]) |> 
        filter(run != "learn") |> 
        select(-c(id, run, condition, cs_stim_time))
    
    data_cond_trial <- data_cond %>% split(.$trial)
    data_cond_trial <- lapply(data_cond_trial, function(x) select(x, -trial))
    
    
    cs_sum_trial <- lapply(data_cond_trial, function(x) apply(x, 2, summary))
    cs_sd_trial <- lapply(data_cond_trial, function(x) apply(x, 2, sd))
    cs_summ_trial <- vector("list", 8)
    for (i in 1:8) {
        cs_summ_trial[[i]] <- rbind(cs_sum_trial[[i]], cs_sd_trial[[i]])
        rownames(cs_summ_trial[[i]]) <-
            c("min", "1stQ", "med", "mean", "3rdQ", "max", "sd")
    }
    
    names(cs_summ_trial) <- paste("trial", 1:8, sep = "_")
    names(data_cond_trial) <- paste("trial", 1:8, sep = "_")
    
    cs_cond_trial_lst[[j]] <- cs_summ_trial
    par(mfrow = c(2, 4), mar = c(4, 4, 2, 1))
    for (k in seq_along(names(data_cond_trial[[1]]))) {
        lapply(1:8, function(x) hist(data_cond_trial[[x]][[k]],
                                     main = paste(names(data_cond_trial)[x], 
                                                  cond_levels[j]),
                                     xlab = cs_var_name[k], las = 1,
                                     font.lab = 2))
    }
}

names(cs_cond_trial_lst) <- cond_levels
lapply(cs_cond_trial_lst, function(x) lapply(x, function(y) round(y, digits = 3)))
```

